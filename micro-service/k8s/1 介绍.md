# k8s 介绍

### 使用k8s的优势:

* 部署升级方便。支持滚动升级、升级失败回退
* 容易拓展。可以根据压力调整应用数量(一个应用的多个实例)
* 负载均衡
* 内置服务发现

### 部署应用到k8s的最简方式:

~~~
kubectl run kubia --image=luksa/kubia --port=8080 --generator=run/v1
~~~

--image 选项指定要运行的docker镜像, --port 告诉k8s应用监听的端口， --generator 指示创建名为kubia的ReplictionController而不是Deployment



### k8s 资源

##### Node

组成k8s集群的物理节点，负责运行Pods

获取集群node列表:

~~~bash
kubectl get nodes
~~~



##### Pods

在k8s中容器不再是独立运行的单位，pod是一个逻辑上的容器组，每个pod内可以包含多个容器（类似容器)。pod可被视为一个独立的逻辑上的机器的，有自己的IP地址、主机名称、进程等。如下图所示

![1584877779541](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\1584877779541.png)



查看pod的ip及在哪个node上运行：

~~~
$ kubectl get pods -o wide
NAME 	READY 	STATUS 	RESTARTS 	AGE 	IP 			NODE
kubia-hczji 1/1 Running 	0 		7s 		10.1.0.2 	gke-kubia-85...
~~~





获取pod的详细信息:

~~~bash
$ kubectl describe pod kubia-hczji
Name: kubia-hczji
Namespace: default
Node: gke-kubia-85f6-node-vs9f/10.132.0.3
Start Time: Fri, 29 Apr 2016 14:12:33 +0200
Labels: run=kubia
Status: Running
IP: 10.1.0.2
Controllers: ReplicationController/kubia
Containers: ...
Conditions:
Type Status
Ready True
~~~





![1584877827965](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\1584877827965.png)





##### ReplicationController(简写RC)

RC 负责保证Pod的正常运行以及创建Pod的多个副本(横向拓展)。Pod被杀死时，RC会自动创建新的Pod.

获取RC列表：

~~~bash
$ kubectl get replicationcontrollers
NAME DESIRED CURRENT AGE
kubia 1 1 17m

DESIRED 期望的POD数量
CURRENT 当前正在运行的POD数量
~~~



增加Pod副本数量：

~~~bash
$ kubectl scale rc kubia --replicas=3
replicationcontroller "kubia" scaled
~~~



执行上面命令后查看RC状态，期望的副本数量(DESIRED)为3， 正在运行数量(CURRENT)2、

~~~bash
$ kubectl get rc
NAME DESIRED CURRENT READY AGE
kubia 3 3 2 17m


$ kubectl get pods
NAME READY STATUS RESTARTS AGE
kubia-hczji 1/1 Running 0 7s
kubia-iq9y6 0/1 Pending 0 7s
kubia-4jfyf 1/1 Running 0 18m
~~~



##### service 对象(简写SVC)

随着Pod的创建和销毁，pod的ip地址也在改变。要访问pod必须有固定的ip地址，service 正是为这一目的诞生。service为Pods提供固定的地址，客户端通过访问service的固定地址，来访问pod。若pod有多个副本，service还有负载均衡的作用。来自客户端的请求会随机的递送到其中的一个Pod。如下图所示



![1584880095948](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\1584880095948.png)