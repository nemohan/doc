# 测试

### 压力测试

压力测试的目的：

若压力测试的目的仅仅是为了确定服务器能承受的最大压力(比如最高并发)，这种量化并没有什么意义。因为在这种情况之下服务器可能提供的服务水平非常差，甚至不能提供服务。个人认为压力测试是为了确定在提供的服务在可接受范围的临界值时，能承受的压力。一旦确定了压力值就可以为后面的服务伸缩提供依据。



### 性能测试

性能测试的目的

个人认为性能测试的目的是找到某个指标比如吞吐量的最大值，以及对应的负载。随着负载的提升吞吐量也会慢慢提升，但是超过一定的负载后，吞吐量会下降。有了最大的吞吐量之后及对应的负载之后，便可以进行优化或为支持更多负载而提升硬件配置或增加服务器数目。

以下面图为例，当水量非常少时，没有达到管道的瓶颈(最大吞吐量)。随着水量增多管道的吞吐量慢慢增长，最终会达到管道的最大吞吐量，此时水量的增加则不会影响管道的吞吐量。服务器的吞吐量在达到最大值之前跟下面的过程相似。但是达到最大值之后，服务器的表现不同

~~~
			水
      |			|
	  |         |  容器
	   \	   /
		\     /
 		 \   /
 		 |   | 管道
 		 |   |
 
~~~



### 服务器性能量化指标

以web服务器为例

##### 常见的量化指标

QPS: query per second（每秒查询次数)

吞吐量:



##### 单并发下一个接口的吞吐量

一个查询接口每秒能够执行的次数应该就是QPS，同时也是这个接口的吞吐量。在单并发条件下得到接口一次执行的耗费的时间，就可以近似得到该接口在单并发条件下的吞吐量。不必使用工具

##### 高并发下单接口的吞吐量

如何得到高并发下比较准确的吞吐量，以jmeter为例。

线程组设定:

* 设定线程(用户)数为500

* Ramp-Up: 10秒。官方解释是500/10=50即每20毫秒启动一个线程。我的疑问是启动时的10秒之内，每20毫秒启动一个线程，10秒之后则是500个线程一起运行么
* 循环100次。每次启动500个线程还是每个线程执行100次请求。应该是后者

方式一：单个线程的执行步骤

* 请求接口
* 收到响应
* 重复上面2步

这种方式得到的吞吐量由两个部分组成：单个线程在1sec之内的请求次数；1sec之内发起请求的线程数目

方式二：单个线程执行步骤

* 请求接口
* 收到响应
* 线程结束

这种方式得到的吞吐量主要取决于1sec之内发起请求的线程数目

貌似使用第二种方式能获得比较准确的高并发下的吞吐量



##### 单接口的QPS或吞吐量意味着什么？

意味着每秒能够处理多少个请求

假设接口的QPS或吞吐量为20/sec。处理1000个请求则需要50sec。

* 单用户1000个请求，第1000个请求则等待近50sec。
* <font color="red">1000个用户，每个用户1个请求若1000个用户同时请求此接口，是否意味着第1000个被执行的请求，将等待近50秒。这种情况响应时间满足 50ms< resp_time < 50s。协程的并发非并行决定了响应时间一定大于50ms。 </font>






### 疑惑

假设使用golang,同时开启500个协程（单物理机)，来模拟500用户并发。

* 多线程(协程)压测客户端能不能准确模拟真实的高并发环境



测试环境：

* 应该将服务器和压测客户端同放在局域网内
* 服务器在外网，客户端在本地

##### 在高并发情况下，多线程(协程)的压测客户端确定的请求响应时间受线程(协程)调度器影响。随着线程(协程)数目的增多误差增大。所以只能通过工具得到一个比较模糊的数值

以go的协程为例，调度器对准确度的影响有多大

#### <font color="red">案例分析--废弃</font>

<font color="blue"> 原因: go的http包复用了连接。并非每个协程开启了一个新的tcp连接</font>

环境: 服务器在阿里云，测试端在本地。本地跟服务器位置没有跨省

Round-Trip: 4-16ms

golang同时开启1000个协程，请求web服务器数据，代码如下

~~~golang
func main() {
	for i := 30104; i < 30105+1000; i++ {
		go doRequest(i)
	}
	time.Sleep(time.Second * 120)
}
~~~



测试结果:

10秒1000个请求

~~~

id:30748 8697 start:2019-10-26 11:41:31.5727011 +0800 CST m=+0.015989601 end:2019-10-26 11:41:40.2701623 +0800 CST m=+8.713450801
id:30406 8709 start:2019-10-26 11:41:31.5697039 +0800 CST m=+0.012992401 end:2019-10-26 11:41:40.2791778 +0800 CST m=+8.722466301
id:30879 8704 start:2019-10-26 11:41:31.5747011 +0800 CST m=+0.017989601 end:2019-10-26 11:41:40.2791778 +0800 CST m=+8.722466301
id:30593 8706 start:2019-10-26 11:41:31.5727011 +0800 CST m=+0.015989601 end:2019-10-26 11:41:40.2791778 +0800 CST m=+8.722466301
id:31006 8704 start:2019-10-26 11:41:31.5747011 +0800 CST m=+0.017989601 end:2019-10-26 11:41:40.2791778 +0800 CST m=+8.722466301
id:30158 8714 start:2019-10-26 11:41:31.5647173 +0800 CST m=+0.008005801 end:2019-10-26 11:41:40.2791778 +0800 CST m=+8.722466301
id:30306 8723 start:2019-10-26 11:41:31.5657004 +0800 CST m=+0.008988901 end:2019-10-26 11:41:40.2891662 +0800 CST m=+8.732454701
id:30268 8720 start:2019-10-26 11:41:31.5687014 +0800 CST m=+0.011989901 end:2019-10-26 

以此请求为例，从服务器日志看。从接收到返回数据只用了10毫秒，那么剩下的9秒多用到哪里了
id:30285 9962 start:2019-10-26 11:41:31.570701 +0800 CST m=+0.013989501 end:2019-10-26 11:41:41.532875 +0800 CST m=+9.976163501

~~~



单协程版本

~~~golang
func main() {
	now := time.Now()
	for i := 30104; i < 30105+1000; i++ {
		doRequest(i)
	}
	fmt.Printf("======== start:%s  end:%s\n", now, time.Now())
	time.Sleep(time.Second * 120)
}
~~~



分析：

开启500个协程模拟真实场景的用户是有误差的，首先500个协程并非并行执行，而是并发。并发就意味着调度器的性能在某种程度上影响着



### jmeter的执行方式

线程组：tearDown线程组。

线程数目: 10

Ramp-Up: 10

循环: 2

观察到的结果:

一共执行了10秒，每秒2个请求。每个请求使用了新的TCP连接

线程数目:10

Ramp-Up: 10

循环：3

结果:

一共执行了10秒，每秒3个请求，每个请求使用了新的TCP连接。

##### 结论：

请求总数: 线程数目 * 循环次数

每秒请求数:  (线程数目 / Ramp-Up) * 循环次数

如果jmeter压测得到的吞吐量接近计算而得的每秒请求次数，说明可以继续增加每秒请求次数。增加还是减少可以参照上面的每秒请求数公式

服务器和压测客户端在同一网络时(局域网)：总的请求数一般能在Ramp-Up 设定的时间内完成。

服务器和压测客户端跨广域网络时: 总的请求数的执行时间会超过Ramp-Up.上面的每秒请求数目是否适用？